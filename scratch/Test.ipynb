{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import struct as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_file(image_file):\n",
    "    image_file.seek(0)\n",
    "    magic = st.unpack('>4B', image_file.read(4))\n",
    "\n",
    "    n_images = st.unpack('>I', image_file.read(4))[0]\n",
    "    n_rows = st.unpack('>I', image_file.read(4))[0]\n",
    "    n_columns = st.unpack('>I', image_file.read(4))[0]\n",
    "    n_bytes = n_images * n_rows * n_columns\n",
    "\n",
    "    images = np.zeros((n_images, n_rows * n_columns))\n",
    "    images = np.asarray(st.unpack('>' + 'B' * n_bytes, image_file.read(n_bytes))).reshape((n_images, n_rows * n_columns))\n",
    "\n",
    "    return images\n",
    "\n",
    "def process_label_file(label_file):\n",
    "    label_file.seek(0)\n",
    "    magic = st.unpack('>4B', label_file.read(4))\n",
    "\n",
    "    n_labels = st.unpack('>I', label_file.read(4))[0]\n",
    "\n",
    "    labels = np.zeros((n_labels))\n",
    "    labels = np.asarray(st.unpack('>' + 'B' * n_labels, label_file.read(n_labels)))\n",
    "\n",
    "    targets = np.array([labels]).reshape(-1)\n",
    "\n",
    "    one_hot_labels = np.eye(10)[targets]\n",
    "\n",
    "    return one_hot_labels\n",
    "\n",
    "def dataset():\n",
    "    home = os.path.expanduser('~') + '/Datasets/'\n",
    "\n",
    "    test_images = open(home + 't10k-images-idx3-ubyte', 'rb')\n",
    "    test_labels = open(home + 't10k-labels-idx1-ubyte', 'rb')\n",
    "    train_images = open(home + 'train-images-idx3-ubyte', 'rb')\n",
    "    train_labels = open(home + 'train-labels-idx1-ubyte', 'rb')\n",
    "    \n",
    "    train_images = process_image_file(train_images)\n",
    "    test_images = process_image_file(test_images)\n",
    "    train_labels = process_label_file(train_labels)\n",
    "    test_labels = process_label_file(test_labels)\n",
    "    \n",
    "    return ((train_images, test_images), (train_labels, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.w = np.random.randn(n_inputs, n_neurons).astype(np.float32) * np.sqrt(1. / n_neurons)\n",
    "        self.b = np.zeros((n_neurons))\n",
    "        self.z = np.zeros((n_neurons))\n",
    "        self.d_w = np.zeros((n_inputs, n_neurons))\n",
    "        self.d_b = np.zeros((n_neurons))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z = np.dot(x, self.w) + self.b\n",
    "\n",
    "    def backward(self, error, a):\n",
    "        self.d_w = (1. / n_samples) * np.matmul(error, a)\n",
    "        self.d_b = (1. / n_samples) * np.sum(error.T, axis=1, keepdims=True)\n",
    "\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.a = 0\n",
    "        self.d_a = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.a = np.maximum(0, x)\n",
    "\n",
    "    def backward(self, x):\n",
    "        self.d_a = (x > 0) * 1\n",
    "\n",
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.a = 0\n",
    "        self.d_a = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        exp = np.exp(x - x.max())\n",
    "        self.a = exp / np.sum(exp, axis=0)\n",
    "    \n",
    "    def backward(self, x):\n",
    "        exp = np.exp(x - x.max())\n",
    "        self.d_a = exp / np.sum(exp, axis=0) * (1 - exp / np.sum(exp, axis=0))\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.a = 0\n",
    "        self.d_a = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.a = 1. / (1. + np.exp(-x))\n",
    "\n",
    "    def backward(self, x):\n",
    "        exp = 1. / (1. + np.exp(-x))\n",
    "        self.d_a = exp * (1 - exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_loss(y, a):\n",
    "    l_sum = np.sum(np.multiply(y, np.log(a)))\n",
    "    m = y.shape[1]\n",
    "    l = -(1. / m) * l_sum\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MNIST training data\n",
    "((train_images, test_images), (train_labels, test_labels)) = dataset()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Hyperparameters\n",
    "n_training_examples = 60000\n",
    "n_inputs = 784\n",
    "n_samples = 32\n",
    "n_epochs = 1\n",
    "n_batches = math.floor(n_training_examples / n_samples)\n",
    "learning_rate = 1\n",
    "\n",
    "# Layers\n",
    "layer1 = Dense(n_inputs = n_inputs, n_neurons = 128)\n",
    "activation1 = Sigmoid()\n",
    "layer2 = Dense(n_inputs = 128, n_neurons = 10)\n",
    "activation2 = Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(inputs):\n",
    "    layer1.forward(inputs)\n",
    "    activation1.forward(layer1.z)\n",
    "\n",
    "    layer2.forward(activation1.a)\n",
    "    activation2.forward(layer2.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(x, y):\n",
    "    d_Z2 = activation2.a - y\n",
    "    \n",
    "    layer2.backward(d_Z2.T, activation1.a)\n",
    "    \n",
    "    d_A1 = np.matmul(layer2.w, d_Z2.T)\n",
    "    \n",
    "    activation1.backward(layer1.z)\n",
    "    \n",
    "    d_Z1 = d_A1.T * activation1.d_a\n",
    "    \n",
    "    layer1.backward(d_Z1.T, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (29,128) (32,128) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-e9b5af4ac1d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-264-bf394de77a65>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlayer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mactivation1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlayer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-255-4b41c5d99ba3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (29,128) (32,128) "
     ]
    }
   ],
   "source": [
    "for j in range(n_epochs):\n",
    "    shuffle_index = np.random.permutation(n_training_examples)\n",
    "\n",
    "    for batch_start in shuffle_index:\n",
    "        batch_end = batch_start + n_samples\n",
    "\n",
    "        batch_x = train_images[batch_start:batch_end]\n",
    "        batch_y = train_labels[batch_start:batch_end]\n",
    "\n",
    "        forward(batch_x)\n",
    "        backward(batch_x, batch_y)\n",
    "        \n",
    "        layer1.w = layer1.w - learning_rate * layer1.d_w.T\n",
    "        layer1.b = layer1.b - learning_rate * layer1.d_b\n",
    "        layer2.w = layer2.w - learning_rate * layer2.d_w.T\n",
    "        layer2.b = layer2.b - learning_rate * layer2.d_b\n",
    "\n",
    "    forward(test_images)\n",
    "    test_loss = batch_loss(test_labels, activation2.a)\n",
    "\n",
    "    print(\"€poch {}, test loss: {}\", format(j + 1), format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
